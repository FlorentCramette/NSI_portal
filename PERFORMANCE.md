# üöÄ Performance et Scalabilit√© - Portail NSI

## üìä Analyse de la capacit√© actuelle

### ‚úÖ Points forts existants

1. **Architecture client-side** 
   - ‚úÖ Pyodide et sql.js s'ex√©cutent dans le navigateur
   - ‚úÖ Pas de charge serveur pour l'ex√©cution de code
   - ‚úÖ R√©duit drastiquement la charge CPU/m√©moire c√¥t√© serveur

2. **Base de donn√©es optimis√©e**
   - ‚úÖ PostgreSQL avec pooling de connexions (`conn_max_age=600`)
   - ‚úÖ `select_related()` utilis√© dans les vues principales
   - ‚úÖ Index sur les cl√©s √©trang√®res

3. **Configuration production**
   - ‚úÖ Gunicorn avec 3 workers par d√©faut
   - ‚úÖ WhiteNoise pour les fichiers statiques
   - ‚úÖ Timeout de 120s

### ‚ö†Ô∏è Points √† am√©liorer pour 50+ utilisateurs simultan√©s

## üéØ Optimisations recommand√©es

### 1. **Cache Redis** (Priorit√© HAUTE)

**Probl√®me actuel :** Chaque requ√™te charge les donn√©es depuis PostgreSQL

**Solution :**
```python
# Installation
# requirements.txt
django-redis==5.4.0
redis==5.0.1

# settings_prod.py
CACHES = {
    'default': {
        'BACKEND': 'django_redis.cache.RedisCache',
        'LOCATION': os.environ.get('REDIS_URL', 'redis://127.0.0.1:6379/1'),
        'OPTIONS': {
            'CLIENT_CLASS': 'django_redis.client.DefaultClient',
            'CONNECTION_POOL_KWARGS': {
                'max_connections': 50,
                'retry_on_timeout': True,
            }
        },
        'KEY_PREFIX': 'nsi_portal',
        'TIMEOUT': 300,  # 5 minutes par d√©faut
    }
}

# Cache des sessions en Redis
SESSION_ENGINE = 'django.contrib.sessions.backends.cache'
SESSION_CACHE_ALIAS = 'default'
```

**Impact :** R√©duit de 60-80% la charge sur PostgreSQL

### 2. **Database Connection Pool** (Priorit√© HAUTE)

```python
# settings_prod.py
DATABASES = {
    'default': {
        # ... configuration existante ...
        'CONN_MAX_AGE': 600,  # ‚úÖ D√©j√† configur√©
        'OPTIONS': {
            'connect_timeout': 10,
            'options': '-c statement_timeout=30000',  # 30s timeout
        },
        # Ajouter pgbouncer en production pour pooling avanc√©
    }
}
```

### 3. **Optimisation des requ√™tes** (Priorit√© MOYENNE)

**Probl√®mes d√©tect√©s :**
- V√©rification des badges √† chaque soumission r√©ussie
- Pas de prefetch pour les relations many-to-many

**Solutions :**

```python
# exercises/views.py - Optimiser SubmitAttemptView
def post(self, request, pk):
    # Utiliser select_for_update pour √©viter race conditions
    exercise = Exercise.objects.select_related('chapter').get(pk=pk)
    
    # Batch les v√©rifications de badges (faire en t√¢che async)
    if passed:
        from django.core.cache import cache
        
        # V√©rifier si d√©j√† gagn√© (cache)
        cache_key = f'user_first_pass_{user.id}_{exercise.id}'
        is_first_pass = cache.get(cache_key)
        
        if is_first_pass is None:
            is_first_pass = not exercise.attempts.filter(
                user=user, passed=True
            ).exists()
            cache.set(cache_key, is_first_pass, 3600)
```

### 4. **Gunicorn configuration avanc√©e** (Priorit√© HAUTE)

```python
# start.py - Am√©liorer la configuration Gunicorn
workers = int(os.environ.get('WEB_CONCURRENCY', '4'))  # 2*CPU+1
worker_class = 'gthread'  # Support des threads
threads = int(os.environ.get('GUNICORN_THREADS', '2'))
worker_connections = 1000
max_requests = 1000  # Red√©marrage apr√®s 1000 requ√™tes
max_requests_jitter = 50  # Variation al√©atoire
keepalive = 5

cmd = [
    "gunicorn",
    "nsi_project.wsgi:application",
    "--bind", f"0.0.0.0:{port}",
    "--workers", str(workers),
    "--worker-class", worker_class,
    "--threads", str(threads),
    "--worker-connections", str(worker_connections),
    "--max-requests", str(max_requests),
    "--max-requests-jitter", str(max_requests_jitter),
    "--keepalive", str(keepalive),
    "--timeout", "120",
    "--access-logfile", "-",
    "--error-logfile", "-",
    "--log-level", "info",
]
```

### 5. **Compression et CDN** (Priorit√© MOYENNE)

```python
# settings_prod.py
MIDDLEWARE = [
    'django.middleware.security.SecurityMiddleware',
    'whitenoise.middleware.WhiteNoiseMiddleware',
    'django.middleware.gzip.GZipMiddleware',  # ‚úÖ AJOUTER
    # ... reste
]

# Compression WhiteNoise
STATICFILES_STORAGE = 'whitenoise.storage.CompressedManifestStaticFilesStorage'

# Caching headers pour statiques
WHITENOISE_MAX_AGE = 31536000  # 1 an
```

### 6. **Monitoring et limites** (Priorit√© HAUTE)

```python
# Installation
# pip install django-ratelimit

# settings_prod.py
RATELIMIT_ENABLE = True
RATELIMIT_USE_CACHE = 'default'

# exercises/views.py
from django_ratelimit.decorators import ratelimit

@method_decorator(ratelimit(key='user', rate='100/h', method='POST'), name='dispatch')
class SubmitAttemptView(LoginRequiredMixin, View):
    """Limite √† 100 soumissions par heure par utilisateur"""
    pass
```

### 7. **T√¢ches asynchrones** (Priorit√© MOYENNE)

Pour les op√©rations lourdes (badges, achievements, emails) :

```python
# Installation
# pip install celery redis

# settings_prod.py
CELERY_BROKER_URL = os.environ.get('REDIS_URL', 'redis://localhost:6379/0')
CELERY_RESULT_BACKEND = CELERY_BROKER_URL
CELERY_TASK_SERIALIZER = 'json'
CELERY_ACCEPT_CONTENT = ['json']
CELERY_TIMEZONE = 'Europe/Paris'

# D√©placer v√©rification badges en t√¢che async
from celery import shared_task

@shared_task
def check_user_badges_achievements(user_id):
    user = User.objects.get(id=user_id)
    # V√©rification badges et achievements
    pass
```

## üìà Capacit√© estim√©e avec optimisations

### Avant optimisations (√©tat actuel)
- **10-15 utilisateurs simultan√©s** : ‚úÖ OK
- **20-30 utilisateurs simultan√©s** : ‚ö†Ô∏è Possible mais lent
- **50+ utilisateurs simultan√©s** : ‚ùå Risque de timeout

**Goulets d'√©tranglement :**
- Connexions DB limit√©es
- Pas de cache
- V√©rifications synchrones lourdes

### Apr√®s optimisations (avec Redis + Config Gunicorn)
- **50 utilisateurs simultan√©s** : ‚úÖ OK
- **100 utilisateurs simultan√©s** : ‚úÖ OK
- **200+ utilisateurs simultan√©s** : ‚ö†Ô∏è N√©cessite scaling horizontal

**Configuration Railway recommand√©e :**
- **Postgres** : Hobby plan (1 GB RAM minimum)
- **Redis** : Instance Redis (512 MB minimum)
- **Web Service** : 1 GB RAM, 1 vCPU minimum

## üîß Plan d'impl√©mentation rapide

### Phase 1 : Optimisations imm√©diates (30 min)
1. ‚úÖ Augmenter workers Gunicorn √† 4
2. ‚úÖ Activer GZip compression
3. ‚úÖ Ajouter rate limiting basique

### Phase 2 : Cache Redis (1-2h)
1. Ajouter Redis sur Railway
2. Configurer django-redis
3. Cacher les cours, chapitres, exercices
4. Sessions en Redis

### Phase 3 : Optimisation DB (1h)
1. Ajouter prefetch_related o√π n√©cessaire
2. Cr√©er index manquants
3. Optimiser les requ√™tes lourdes

### Phase 4 : T√¢ches async (2-3h)
1. Setup Celery + Redis
2. D√©placer v√©rifications badges en async
3. Emails en async

## üß™ Tests de charge recommand√©s

```bash
# Installer locust
pip install locust

# Cr√©er locustfile.py
from locust import HttpUser, task, between

class NSIUser(HttpUser):
    wait_time = between(1, 3)
    
    @task(3)
    def view_courses(self):
        self.client.get("/courses/")
    
    @task(2)
    def view_chapter(self):
        self.client.get("/courses/chapter/nsi-1-python-bases/")
    
    @task(1)
    def submit_exercise(self):
        self.client.post("/exercises/1/submit/", json={
            "passed": True,
            "score": 100
        })

# Lancer le test
# locust -f locustfile.py --host=https://votre-app.railway.app
```

## üìä M√©triques √† surveiller

1. **Temps de r√©ponse moyen** : < 200ms
2. **Temps de r√©ponse P95** : < 1s
3. **Utilisation CPU** : < 70%
4. **Utilisation RAM** : < 80%
5. **Connexions DB actives** : < 80% du pool
6. **Hit rate cache Redis** : > 80%

## üéØ Verdict : 50 utilisateurs simultan√©s ?

### Configuration ACTUELLE (dev)
- **R√©ponse** : ‚ùå **NON**, risque de timeouts et lenteurs
- **Limite estim√©e** : 10-15 utilisateurs simultan√©s

### Avec optimisations MINIMALES (Phase 1 + 2)
- **R√©ponse** : ‚úÖ **OUI**, confortablement
- **Capacit√©** : 50-100 utilisateurs simultan√©s

### Configuration RECOMMAND√âE pour production
```yaml
# railway.toml
[build]
builder = "DOCKERFILE"

[deploy]
startCommand = "python start.py"
restartPolicyType = "ON_FAILURE"
restartPolicyMaxRetries = 10

[env]
WEB_CONCURRENCY = "4"
GUNICORN_THREADS = "2"
DJANGO_SETTINGS_MODULE = "nsi_project.settings_prod"

# Services requis
# - PostgreSQL (Hobby: $5/mo)
# - Redis (512MB: $5/mo)
# - Web Service (1GB RAM: $5/mo)
```

## ‚úÖ Actions prioritaires MAINTENANT

1. **Ajouter Redis** - Impact imm√©diat maximum
2. **Optimiser Gunicorn** - Configuration simple
3. **Ajouter monitoring** - Sentry ou √©quivalent
4. **Rate limiting** - Protection essentielle

**Temps total d'impl√©mentation** : 2-4 heures
**Co√ªt mensuel Railway** : ~$15-20 avec Redis

## üìö Ressources

- [Django Performance Tips](https://docs.djangoproject.com/en/5.0/topics/performance/)
- [Gunicorn Configuration](https://docs.gunicorn.org/en/stable/settings.html)
- [Railway Scaling Guide](https://docs.railway.app/reference/scaling)
- [Django-Redis Documentation](https://github.com/jazzband/django-redis)
